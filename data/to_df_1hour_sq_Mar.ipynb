{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def open_files(date):\n",
    "    focus_text = \"2018-03-\" + date + \"_focus/2018-03-\" + \\\n",
    "                 date + \"_focus_group.json\"\n",
    "    krx_text = \"krx_code.json\"\n",
    "    price_text = \"2018-03-\" + date + \"_price_and_everything.json\"\n",
    "    \n",
    "    with open(focus_text, 'r', encoding='UTF-8') as focus_group:\n",
    "        focus = json.load(focus_group)\n",
    "    with open(krx_text, 'r', encoding='UTF-8') as krx:\n",
    "        krx_code = json.load(krx)\n",
    "    with open(price_text, 'r', encoding='UTF-8') as pnc:\n",
    "        price = json.load(pnc)\n",
    "    \n",
    "    return focus, krx_code, price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_time_disc(date):\n",
    "    \n",
    "    time = []\n",
    "    prefix = \"2018-03-\" + date + \"_focus/discussion_2018-03-\" + date\n",
    "    \n",
    "    for hour in range(9,16):\n",
    "        \n",
    "        if date == \"02\" and hour == 9:\n",
    "            continue\n",
    "        \n",
    "        elif date == \"02\" and hour == 10:\n",
    "            continue\n",
    "        \n",
    "        elif date == \"02\" and hour == 15:\n",
    "            continue\n",
    "            \n",
    "        for minute in range(0, 6):\n",
    "            if date == \"02\" and hour == 11 and minute < 5:\n",
    "                continue\n",
    "            \n",
    "            elif date == \"02\" and hour == 14 and minute > 4:\n",
    "                continue\n",
    "            \n",
    "            time.append(prefix + \" \" + ((\"0\" + str(hour)) if hour <= 9 else str(hour))+ \\\n",
    "                        \":\" + str(minute) + \"0.json\")\n",
    "            \n",
    "            if hour == 15 and minute > 3:\n",
    "                del time[len(time) - 1]\n",
    "    \n",
    "    return time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def df_list_dis(date):\n",
    "    df_list = []\n",
    "    time = get_time_disc(date)\n",
    "    for x in time:\n",
    "        with open(x, 'r', encoding='UTF-8') as f:\n",
    "            discussion = json.load(f)        \n",
    "            discuss_df = pd.DataFrame(discussion, columns = [\"post_num\", \\\n",
    "                                \"unique_id\", \"click\", \"like\", \"dislike\", \n",
    "                                \"name\", \"time\"])\n",
    "            reset_col = [\"name\", \"time\", \"post_num\", \"unique_id\", \"click\", \\\n",
    "                         \"like\", \"dislike\"]\n",
    "            discuss_df = discuss_df[reset_col]\n",
    "            df_list.append(discuss_df)\n",
    "    return df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#half an hour high freq\\ndef list_to_df(date, df_list, column_names, key_list):\\n    total = pd.DataFrame(columns=column_names)\\n    for ind, df in enumerate(df_list):\\n        if ind >= 5:\\n            df_total = df.merge(df_list[ind - 5], on =                                 key_list).merge(df_list[ind - 4],                                 on = key_list).merge(df_list[ind - 3], on = key_list)\\n            df_total.columns = column_names\\n            total = pd.concat([total, df_total], axis = 0)\\n    \\n    return total\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#half an hour high freq\n",
    "def list_to_df(date, df_list, column_names, key_list):\n",
    "    total = pd.DataFrame(columns=column_names)\n",
    "    for ind, df in enumerate(df_list):\n",
    "        if ind >= 5:\n",
    "            df_total = df.merge(df_list[ind - 5], on = \\\n",
    "                                key_list).merge(df_list[ind - 4], \\\n",
    "                                on = key_list).merge(df_list[ind - 3], on = key_list)\n",
    "            df_total.columns = column_names\n",
    "            total = pd.concat([total, df_total], axis = 0)\n",
    "    \n",
    "    return total\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#one hour high freq\n",
    "def list_to_df(date, df_list, column_names, key_list):\n",
    "    total = pd.DataFrame(columns=column_names)\n",
    "    for ind, df in enumerate(df_list):\n",
    "        if ind >= 8:\n",
    "            df_total = df.merge(df_list[ind - 8], on = \\\n",
    "                                key_list).merge(df_list[ind - 7], \\\n",
    "                                on = key_list).merge(df_list[ind - 6], on = key_list)\n",
    "            df_total.columns = column_names\n",
    "            total = pd.concat([total, df_total], axis = 0)\n",
    "    \n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "COLUMN_DISC =[\"name\", \"time\", \"post_num\", \"unique_id\", \"click\", \\\n",
    "              \"like\", \"dislike\", \"time_1\", \"post_num_1\", \"unique_id_1\", \"click_1\", \\\n",
    "              \"like_1\", \"dislike_1\", \"time_2\", \"post_num_2\", \"unique_id_2\", \"click_2\", \\\n",
    "              \"like_2\", \"dislike_2\", \"time_3\", \"post_num_3\", \"unique_id_3\", \"click_3\", \\\n",
    "              \"like_3\", \"dislike_3\"]\n",
    "\n",
    "def get_discuss_df(date):\n",
    "    discussion_list = df_list_dis(date)\n",
    "    discuss_df = list_to_df(date, discussion_list, COLUMN_DISC, \n",
    "                            ['name']).reset_index().drop([\"index\"], axis = 1)\n",
    "    return discuss_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def df_list_price(date):\n",
    "    price_df = pd.DataFrame(price, columns = [\"index\", \"code\", \"name\", \"time\", \"price\", \\\n",
    "                                         \"price_dif\", \"sell\", \"buy\", \"volume\", \"variation\"])\n",
    "    price_df = price_df[[\"code\", \"name\", \"time\", \"price\", \\\n",
    "                    \"price_dif\", \"sell\", \"buy\", \"volume\", \"variation\"]][1:]\n",
    "    text = \"2018-03-\" + date + \" 09:00\"\n",
    "    price_df = price_df[price_df[\"time\"] != text]\n",
    "    time_list = price_df['time'].unique().tolist()\n",
    "    price_df_list = []\n",
    "    for time in time_list:\n",
    "        df = price_df[price_df[\"time\"] == time]\n",
    "        df = df[[\"code\", \"name\", \"time\", \"price\", \\\n",
    "                \"price_dif\", \"sell\", \"buy\", \"volume\", \"variation\"]]\n",
    "        price_df_list.append(df)\n",
    "        \n",
    "    return price_df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "COLUMN_PRICE=[\"code\", \"name\", \"time\", \"price\", \"price_dif\", \"sell\", \n",
    "              \"buy\", \"volume\", \"variation\", \"time_1\", \"price_1\", \n",
    "              \"price_dif_1\", \"sell_1\", \"buy_1\", \"volume_1\", \"variation_1\",\n",
    "              \"time_2\", \"price_2\", \"price_dif_2\", \"sell_2\", \"buy_2\", \n",
    "              \"volume_2\", \"variation_2\", \"time_3\", \"price_3\", \n",
    "              \"price_dif_3\", \"sell_3\", \"buy_3\", \"volume_3\", \"variation_3\"]\n",
    "\n",
    "def get_price_df(date):\n",
    "    price_df_list = df_list_price(date)\n",
    "    price_df = list_to_df(date, price_df_list, COLUMN_PRICE, \\\n",
    "                          ['code', 'name']).reset_index().drop([\"index\"], axis = 1)\n",
    "    \n",
    "    return price_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "COLUMN_TOTAL = ['name', 'code', 'time', 'price', 'time_1', \"price_1\", \\\n",
    "                \"price_dif_1\", \"sell_1\", \"buy_1\", \"volume_1\", \"variation_1\", \\\n",
    "                'post_num_1', 'unique_id_1', 'click_1', 'like_1', 'dislike_1', \\\n",
    "                'time_2', 'price_2', \"price_dif_2\", \"sell_2\", \"buy_2\", \\\n",
    "                \"volume_2\", \"variation_2\", 'post_num_2', 'unique_id_2', 'click_2', \\\n",
    "                'like_2', 'dislike_2', 'time_3', 'price_3', \"price_dif_3\", \\\n",
    "                \"sell_3\", \"buy_3\", \"volume_3\", \"variation_3\", 'post_num_3', \\\n",
    "                'unique_id_3', 'click_3', 'like_3', 'dislike_3']\n",
    "\n",
    "def get_total_df(date):\n",
    "    price_df = get_price_df(date)\n",
    "    discuss_df = get_discuss_df(date)\n",
    "    total_df = pd.merge(price_df, discuss_df, on = ['name', \\\n",
    "                                                    'time', 'time_1', 'time_2', 'time_3'])\n",
    "    total_df = total_df[COLUMN_TOTAL]\n",
    "    \n",
    "    return total_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "\n",
    "with open(\"company_size.json\", 'r', encoding='UTF-8') as f:\n",
    "    company_size = json.load(f)\n",
    "\n",
    "company_df = pd.DataFrame({\"company_name\": np.zeros(0), \\\n",
    "                           \"code\": np.zeros(0), \"market\": np.zeros(0), \n",
    "                          \"company_size\": np.zeros(0)})\n",
    "\n",
    "company_df = pd.DataFrame(company_size, columns = [\"name\", \"code\", \"market\", \"size\"])\n",
    "\n",
    "KOSPI = []\n",
    "KOSDAQ = []\n",
    "TRASH = []\n",
    "MKT_CAP = {}\n",
    "\n",
    "for idx, row in company_df.iterrows():\n",
    "    if re.sub('[0-9 ,위]', '', row[\"market\"]) == \"코스피\":\n",
    "        KOSPI.append(row[\"code\"])\n",
    "    elif re.sub('[0-9 ,위]', '', row[\"market\"]) == \"코스닥\":\n",
    "        KOSDAQ.append(row[\"code\"])\n",
    "    else:\n",
    "        TRASH.append(row[\"code\"])\n",
    "    \n",
    "    MKT_CAP[row[\"code\"]] = int(re.sub('[조억원,]', '', row[\"size\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_company(date):\n",
    "    \n",
    "    total = get_total_df(date)\n",
    "    total[\"mkt_cap\"] = np.nan\n",
    "    total[\"kospi\"] = np.nan\n",
    "    total[\"kosdaq\"] = np.nan\n",
    "    total[\"trash\"] = np.nan\n",
    "    \n",
    "    for index, row in total.iterrows():\n",
    "        mkt_cap = MKT_CAP[row[\"code\"]]\n",
    "        if row[\"code\"] in KOSPI:\n",
    "            kospi = 1\n",
    "        else:\n",
    "            kospi = 0\n",
    "\n",
    "        if row[\"code\"] in KOSDAQ:\n",
    "            kosdaq = 1\n",
    "        else:\n",
    "            kosdaq = 0\n",
    "\n",
    "        if row[\"code\"] in TRASH:\n",
    "            trash = 1\n",
    "        else:\n",
    "            trash = 0\n",
    "        total.set_value(index,'mkt_cap', mkt_cap)\n",
    "        total.set_value(index,'kospi', kospi)\n",
    "        total.set_value(index,'kosdaq', kosdaq)\n",
    "        total.set_value(index,'trash', trash)  \n",
    "    \n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_df(date):\n",
    "    \n",
    "    total = add_company(date)\n",
    "    total.dropna(inplace = True)\n",
    "    var_to_transform = ['price', 'price_1', 'price_dif_1', 'sell_1', \n",
    "                        'buy_1', 'volume_1', 'variation_1', 'price_2', \n",
    "                        'price_dif_2', 'sell_2', 'buy_2', 'volume_2', \n",
    "                        'variation_2', 'price_3', 'price_dif_3', 'sell_3', 'buy_3', \n",
    "                        'volume_3', 'variation_3']\n",
    "    for var in var_to_transform:\n",
    "        total = total[total[var] != '\\xa0']\n",
    "        for index, row in total.iterrows():\n",
    "            if isinstance(row[var], str):\n",
    "                data = row[var].split(\",\")\n",
    "                value = ''.join(data)\n",
    "                value = int(value)\n",
    "                total.set_value(index, var, value)\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "focus, krx_code, price = open_files('02')\n",
    "total_02 = transform_df('02')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'del_time = [\"2018-02-27 11:30\", \"2018-02-27 11:40\", \"2018-02-27 11:50\", \"2018-02-27 12:00\", \"2018-02-27 12:10\",             \"2018-02-27 12:20\", \"2018-02-27 12:30\", \"2018-02-27 12:40\", \"2018-02-27 12:50\", \"2018-02-27 13:00\",             \"2018-02-27 13:10\", \"2018-02-27 13:20\", \"2018-02-27 13:30\", \"2018-02-27 13:40\"]\\ntotal_27 = total_27[~total_27[\\'time\\'].isin(del_time)]'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''del_time = [\"2018-02-27 11:30\", \"2018-02-27 11:40\", \"2018-02-27 11:50\", \"2018-02-27 12:00\", \"2018-02-27 12:10\", \\\n",
    "            \"2018-02-27 12:20\", \"2018-02-27 12:30\", \"2018-02-27 12:40\", \"2018-02-27 12:50\", \"2018-02-27 13:00\", \\\n",
    "            \"2018-02-27 13:10\", \"2018-02-27 13:20\", \"2018-02-27 13:30\", \"2018-02-27 13:40\"]\n",
    "total_27 = total_27[~total_27['time'].isin(del_time)]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_df = pd.concat([total_02])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_df = total_df.reset_index().drop([\"index\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_df[\"yesterday_closing_price\"] = total_df[\"price_1\"] - total_df[\"price_dif_1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_df[\"is_maximum\"] = (((total_df[\"price_1\"] / total_df[\"yesterday_closing_price\"]) - 1) * 100 > 29.5) | \\\n",
    "(((total_df[\"price_2\"] / total_df[\"yesterday_closing_price\"]) - 1) * 100 > 29.5) | \\\n",
    "(((total_df[\"price_3\"] / total_df[\"yesterday_closing_price\"]) - 1) * 100 > 29.5)\n",
    "total_df[\"is_maximum\"] = total_df[\"is_maximum\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_df[\"is_minimum\"] = (((total_df[\"price_1\"] / total_df[\"yesterday_closing_price\"]) - 1) * 100 < -29.5) | \\\n",
    "(((total_df[\"price_2\"] / total_df[\"yesterday_closing_price\"]) - 1) * 100 < -29.5) | \\\n",
    "(((total_df[\"price_3\"] / total_df[\"yesterday_closing_price\"]) - 1) * 100 < -29.5)\n",
    "total_df[\"is_minimum\"] = total_df[\"is_maximum\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_df[\"price_volatility\"] = (((total_df[[\"price_1\", \"price_2\", \"price_3\"]].max(axis=1)) / (total_df[[\"price_1\", \"price_2\", \"price_3\"]].min(axis=1))) - 1) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_df[\"price_trend\"] = (((total_df[\"price_1\"] - total_df[\"price_2\"]) < 0).astype(int) + ((total_df[\"price_2\"] - total_df[\"price_3\"]) < 0).astype(int)) - (((total_df[\"price_1\"] - total_df[\"price_2\"]) > 0).astype(int) + ((total_df[\"price_2\"] - total_df[\"price_3\"]) > 0).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_df[\"average_price_volatility\"] = total_df[\"price_trend\"] * total_df[\"price_volatility\"] / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_df[\"sell_minus_buy_1\"] = total_df[\"sell_1\"] - total_df[\"buy_1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_df[\"sell_minus_buy_2\"] = total_df[\"sell_2\"] - total_df[\"buy_2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_df[\"sell_minus_buy_3\"] = total_df[\"sell_3\"] - total_df[\"buy_3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_df[\"is_price_gap_stable\"] = ((total_df[\"sell_minus_buy_1\"] == total_df[\"sell_minus_buy_2\"]) & (total_df[\"sell_minus_buy_2\"] == total_df[\"sell_minus_buy_3\"])).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_df[\"price_gap_volatility\"] = (((total_df[[\"sell_minus_buy_1\", \"sell_minus_buy_2\", \"sell_minus_buy_3\"]].max(axis=1)) / (total_df[[\"sell_minus_buy_1\", \"sell_minus_buy_2\", \"sell_minus_buy_3\"]].min(axis=1)))) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_df[\"is_like_higher\"] = (total_df[\"like_3\"] > total_df[\"dislike_3\"]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_df[\"volume_trend\"] = ((((total_df[\"volume_3\"]) - (total_df[\"volume_2\"] * 1+1e-3)) \\\n",
    " / ((total_df[\"volume_2\"]) - (total_df[\"volume_1\"] * 1-1e-4))) - 1) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_df[\"post_num_trend\"] = ((((total_df[\"post_num_3\"]) - (total_df[\"post_num_2\"] * 1+1e-3)) \\\n",
    " / ((total_df[\"post_num_2\"]) - (total_df[\"post_num_1\"] * 1-1e-4))) - 1) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_df[\"unique_id_trend\"] = ((((total_df[\"unique_id_3\"]) - (total_df[\"unique_id_2\"] * 1+1e-3)) \\\n",
    " / ((total_df[\"unique_id_2\"]) - (total_df[\"unique_id_1\"] * 1-1e-4))) - 1) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_df[\"click_trend\"] = ((((total_df[\"click_3\"]) - (total_df[\"click_2\"] * 1+1e-3)) \\\n",
    " / ((total_df[\"click_2\"]) - (total_df[\"click_1\"] * 1-1e-4))) - 1) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_df[\"price_increase\"] = ((total_df[\"price\"] / total_df[\"price_3\"]) - 1) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_df[\"did_price_increase\"] = (total_df[\"price_increase\"] > 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_df[\"did_price_033\"] = (total_df[\"price_increase\"] > 0.33).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_df[\"did_price_100\"] = (total_df[\"price_increase\"] > 1.0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_df[\"did_price_150\"] = (total_df[\"price_increase\"] > 1.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('KOSPI_Feb14_Mar02.json', 'r', encoding='UTF-8') as f:\n",
    "    kospi = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('KOSDAQ_Feb14_Mar02.json', 'r', encoding='UTF-8') as f:\n",
    "    kosdaq = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('kospi_now_Feb14_Mar02.json', 'r', encoding='UTF-8') as f:\n",
    "    kospi_now = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('kosdaq_now_Feb14_Mar02.json', 'r', encoding='UTF-8') as f:\n",
    "    kosdaq_now = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_df[\"kospi_ind\"] = np.nan\n",
    "total_df[\"kosdaq_ind\"] = np.nan\n",
    "total_df[\"time_slot\"] = np.nan\n",
    "total_df[\"ko_inter\"] = np.nan\n",
    "total_df[\"early_mor\"] = np.nan\n",
    "total_df[\"morning\"] = np.nan\n",
    "total_df[\"lunch\"] = np.nan\n",
    "total_df[\"afternoon\"] = np.nan\n",
    "total_df[\"late\"] = np.nan\n",
    "total_df[\"mkt_change\"] = np.nan\n",
    "total_df[\"alpha\"] = np.nan\n",
    "total_df['per_now'] = np.nan\n",
    "\n",
    "total_df[\"kospi_1\"] = np.nan\n",
    "total_df[\"kospi_2\"] = np.nan\n",
    "total_df[\"kospi_3\"] = np.nan\n",
    "total_df[\"kospi_answer\"] = np.nan\n",
    "\n",
    "total_df[\"kosdaq_1\"] = np.nan\n",
    "total_df[\"kosdaq_2\"] = np.nan\n",
    "total_df[\"kosdaq_3\"] = np.nan\n",
    "total_df[\"kosdaq_answer\"] = np.nan\n",
    "\n",
    "\n",
    "num = 1\n",
    "time_list = []\n",
    "for index, row in total_df.iterrows():\n",
    "    pi_ind = kospi[row['time']]\n",
    "    daq_ind = kosdaq[row['time']]\n",
    "    total_df.set_value(index,'kospi_ind', pi_ind)\n",
    "    total_df.set_value(index,'kosdaq_ind', daq_ind)\n",
    "    time = row['time'].split()[1]\n",
    "    if time not in time_list:\n",
    "        time_list.append(time)\n",
    "    ind = time_list.index(time)\n",
    "    num = index + 1\n",
    "    \n",
    "    if num in [1, 2, 3]:\n",
    "        early_mor = 1\n",
    "    else:\n",
    "        early_mor = 0\n",
    "    \n",
    "    if (num >= 1) and (num <= 15):\n",
    "        morning = 1\n",
    "    else:\n",
    "        morning = 0\n",
    "        \n",
    "    if (num >= 16) and (num <= 24):\n",
    "        lunch = 1\n",
    "    else:\n",
    "        lunch = 0\n",
    "    \n",
    "    if (num >= 25) and (num <= 36):\n",
    "        afternoon = 1\n",
    "    else:\n",
    "        afternoon = 0\n",
    "    \n",
    "    if (num >= 25) and (num <= 36):\n",
    "        afternoon = 1\n",
    "    else:\n",
    "        afternoon = 0\n",
    "    \n",
    "    if (num >= 31) and (num <= 36):\n",
    "        late = 1\n",
    "    else:\n",
    "        late = 0\n",
    "    \n",
    "\n",
    "    mkt_change = row['kospi'] * pi_ind + row['kosdaq'] * daq_ind\n",
    "    total_df.set_value(index,'mkt_change', mkt_change)\n",
    "    total_df.set_value(index,'early_mor', early_mor)\n",
    "    total_df.set_value(index,'morning', morning)\n",
    "    total_df.set_value(index,'lunch', lunch)\n",
    "    total_df.set_value(index,'afternoon', afternoon)\n",
    "    total_df.set_value(index,'late', late)\n",
    "    total_df.set_value(index,'time_slot', num)\n",
    "    total_df.set_value(index,'ko_inter', pi_ind * daq_ind)\n",
    "    per_now = 100 * row['price_dif_3']/row['yesterday_closing_price']\n",
    "    total_df.set_value(index, 'per_now', per_now)\n",
    "    alpha = per_now - mkt_change\n",
    "    total_df.set_value(index, 'alpha', alpha)\n",
    "    \n",
    "    total_df.set_value(index, 'kospi_1', kospi_now[row[\"time_1\"]])\n",
    "    total_df.set_value(index, 'kospi_2', kospi_now[row[\"time_2\"]])\n",
    "    total_df.set_value(index, 'kospi_3', kospi_now[row[\"time_3\"]])\n",
    "    total_df.set_value(index, 'kospi_answer', kospi_now[row[\"time\"]])\n",
    "    \n",
    "    total_df.set_value(index, 'kosdaq_1', kosdaq_now[row[\"time_1\"]])\n",
    "    total_df.set_value(index, 'kosdaq_2', kosdaq_now[row[\"time_2\"]])\n",
    "    total_df.set_value(index, 'kosdaq_3', kosdaq_now[row[\"time_3\"]])\n",
    "    total_df.set_value(index, 'kosdaq_answer', kosdaq_now[row[\"time\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_df[\"kospi_trend\"] = ((((total_df[\"kospi_3\"]) - (total_df[\"kospi_2\"] * 1+1e-3)) \\\n",
    " / ((total_df[\"kospi_2\"]) - (total_df[\"kospi_1\"] * 1-1e-4))) - 1) * 100\n",
    "\n",
    "total_df[\"kosdaq_trend\"] = ((((total_df[\"kosdaq_3\"]) - (total_df[\"kosdaq_2\"] * 1+1e-3)) \\\n",
    " / ((total_df[\"kosdaq_2\"]) - (total_df[\"kosdaq_1\"] * 1-1e-4))) - 1) * 100\n",
    "\n",
    "total_df[\"kospi_increase\"] = 100 * (total_df[\"kospi_answer\"] - total_df[\"kospi_3\"]) / total_df[\"kospi_3\"]\n",
    "\n",
    "total_df[\"kosdaq_increase\"] = 100 * (total_df[\"kosdaq_answer\"] - total_df[\"kosdaq_3\"]) / total_df[\"kosdaq_3\"]\n",
    "\n",
    "total_df[\"market_increase\"] = (total_df[\"kospi\"] * total_df[\"kospi_increase\"]) \\\n",
    "                            + (total_df[\"kosdaq\"] * total_df[\"kosdaq_increase\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('2018-03-02_opening_increase.json', 'r', encoding='UTF-8') as f:\n",
    "    increase_02 = json.load(f)\n",
    "\n",
    "mar_opening = {\"02\": increase_02}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_df[\"did_opening_price_increase\"] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for index, row in total_df.iterrows():\n",
    "    if row[\"name\"] in mar_opening[row[\"time\"][8:10]]:\n",
    "        total_df.set_value(index,'did_opening_price_increase', 1)\n",
    "    else:\n",
    "        total_df.set_value(index,'did_opening_price_increase', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TO_SQ = ['price_1', 'price_dif_1', 'sell_1', 'buy_1', 'volume_1', 'variation_1', 'post_num_1', 'unique_id_1', 'click_1', 'like_1', 'dislike_1', 'price_2', 'price_dif_2', 'sell_2', 'buy_2', 'volume_2', 'variation_2', 'post_num_2', 'unique_id_2', 'click_2', 'like_2', 'dislike_2', 'price_3', 'price_dif_3', 'sell_3', 'buy_3', 'volume_3', 'variation_3', 'post_num_3', 'unique_id_3', 'click_3', 'like_3', 'dislike_3', 'mkt_cap', 'yesterday_closing_price', 'price_volatility', 'price_trend', 'average_price_volatility', 'sell_minus_buy_1', 'sell_minus_buy_2', 'sell_minus_buy_3', 'price_gap_volatility', 'volume_trend', 'post_num_trend', 'unique_id_trend', 'click_trend', 'kospi_ind', 'kosdaq_ind', 'time_slot', 'ko_inter', 'mkt_change', 'alpha', 'per_now', 'kospi_1', 'kospi_2', 'kospi_3', 'kosdaq_1', 'kosdaq_2', 'kosdaq_3', 'kospi_trend', 'kosdaq_trend']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in TO_SQ:\n",
    "    col_name = var + '_sq'\n",
    "    total_df[col_name] = np.nan\n",
    "    for index, row in total_df.iterrows():\n",
    "        sqr = row[var] ** 2\n",
    "        total_df.set_value(index, col_name, sqr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180\n",
      "180\n"
     ]
    }
   ],
   "source": [
    "print(len(total_df))\n",
    "total_df = total_df.dropna(axis=0, how='any')\n",
    "print(len(total_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['name', 'code', 'time', 'price', 'time_1', 'price_1', 'price_dif_1', 'sell_1', 'buy_1', 'volume_1', 'variation_1', 'post_num_1', 'unique_id_1', 'click_1', 'like_1', 'dislike_1', 'time_2', 'price_2', 'price_dif_2', 'sell_2', 'buy_2', 'volume_2', 'variation_2', 'post_num_2', 'unique_id_2', 'click_2', 'like_2', 'dislike_2', 'time_3', 'price_3', 'price_dif_3', 'sell_3', 'buy_3', 'volume_3', 'variation_3', 'post_num_3', 'unique_id_3', 'click_3', 'like_3', 'dislike_3', 'mkt_cap', 'kospi', 'kosdaq', 'trash', 'yesterday_closing_price', 'is_maximum', 'is_minimum', 'price_volatility', 'price_trend', 'average_price_volatility', 'sell_minus_buy_1', 'sell_minus_buy_2', 'sell_minus_buy_3', 'is_price_gap_stable', 'price_gap_volatility', 'is_like_higher', 'volume_trend', 'post_num_trend', 'unique_id_trend', 'click_trend', 'price_increase', 'did_price_increase', 'did_price_033', 'did_price_100', 'did_price_150', 'kospi_ind', 'kosdaq_ind', 'time_slot', 'ko_inter', 'early_mor', 'morning', 'lunch', 'afternoon', 'late', 'mkt_change', 'alpha', 'per_now', 'kospi_1', 'kospi_2', 'kospi_3', 'kospi_answer', 'kosdaq_1', 'kosdaq_2', 'kosdaq_3', 'kosdaq_answer', 'kospi_trend', 'kosdaq_trend', 'kospi_increase', 'kosdaq_increase', 'market_increase', 'did_opening_price_increase', 'price_1_sq', 'price_dif_1_sq', 'sell_1_sq', 'buy_1_sq', 'volume_1_sq', 'variation_1_sq', 'post_num_1_sq', 'unique_id_1_sq', 'click_1_sq', 'like_1_sq', 'dislike_1_sq', 'price_2_sq', 'price_dif_2_sq', 'sell_2_sq', 'buy_2_sq', 'volume_2_sq', 'variation_2_sq', 'post_num_2_sq', 'unique_id_2_sq', 'click_2_sq', 'like_2_sq', 'dislike_2_sq', 'price_3_sq', 'price_dif_3_sq', 'sell_3_sq', 'buy_3_sq', 'volume_3_sq', 'variation_3_sq', 'post_num_3_sq', 'unique_id_3_sq', 'click_3_sq', 'like_3_sq', 'dislike_3_sq', 'mkt_cap_sq', 'yesterday_closing_price_sq', 'price_volatility_sq', 'price_trend_sq', 'average_price_volatility_sq', 'sell_minus_buy_1_sq', 'sell_minus_buy_2_sq', 'sell_minus_buy_3_sq', 'price_gap_volatility_sq', 'volume_trend_sq', 'post_num_trend_sq', 'unique_id_trend_sq', 'click_trend_sq', 'kospi_ind_sq', 'kosdaq_ind_sq', 'time_slot_sq', 'ko_inter_sq', 'mkt_change_sq', 'alpha_sq', 'per_now_sq', 'kospi_1_sq', 'kospi_2_sq', 'kospi_3_sq', 'kosdaq_1_sq', 'kosdaq_2_sq', 'kosdaq_3_sq', 'kospi_trend_sq', 'kosdaq_trend_sq']\n"
     ]
    }
   ],
   "source": [
    "X = list(total_df.columns)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#total_df.to_json('df_1hour_Mar.json', orient='values')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
