{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import bs4\n",
    "import urllib3\n",
    "from datetime import date\n",
    "import re\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# code by KI to get stock codes or import a csv file\n",
    "import pandas as pd \n",
    "code_df = pd.read_html('http://kind.krx.co.kr/corpgeneral/corpList.do?method=download&searchType=13', header=0)[0]\n",
    "code_df.종목코드 = code_df.종목코드.map('{:06d}'.format)\n",
    "code_df = code_df[['회사명', '종목코드']]\n",
    "code_df = code_df.rename(columns={'회사명': 'name', '종목코드': 'code'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_max_page(code):\n",
    "    \n",
    "    target = \"http://finance.naver.com/item/board.nhn?code=\" + code + \"&page=1\"\n",
    "    pm = urllib3.PoolManager()\n",
    "    html = pm.urlopen(url=target, method=\"GET\").data\n",
    "    soup = bs4.BeautifulSoup(html, 'lxml')\n",
    "    a_tag = soup.find_all(\"a\")\n",
    "    for a in a_tag:\n",
    "        if a.has_attr(\"href\") and a.text.strip(\"\\n\\t\") == \"맨뒤\":\n",
    "            target_tag = a\n",
    "    text = target_tag[\"href\"]\n",
    "    match=re.search('[\\d]+$',text)\n",
    "    max_page = match.group()\n",
    "    \n",
    "    return max_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scrape_discussion(code):\n",
    "    page_num = 1\n",
    "    post_list = []\n",
    "    while page_num <= int(get_max_page(code)): ###\n",
    "        target = \"http://finance.naver.com/item/board.nhn?code=\" + code + \"&page=\" + str(page_num)\n",
    "        pm = urllib3.PoolManager()\n",
    "        html = pm.urlopen(url=target, method=\"GET\").data\n",
    "        soup = bs4.BeautifulSoup(html, 'lxml')\n",
    "        div_tag = soup.find_all(\"div\", class_ =\"section inner_sub\")\n",
    "        div_row = div_tag[0].find_all(\"tr\")\n",
    "        post_list = []\n",
    "        for row in div_row[2:25]:\n",
    "            if div_row.index(row) not in [7, 13, 19]:\n",
    "                post_dic = {}\n",
    "                info_list = row.find_all('td')\n",
    "                time = info_list[0].text\n",
    "                date_list = time.split(\" \")[0].split(\".\")\n",
    "                pre_date = date(int(date_list[0]), int(date_list[1]), int(date_list[2]))\n",
    "                today = date.today()\n",
    "                if (today - pre_date).days <= 10: ###set a day\n",
    "                    post_dic[\"time\"] = time\n",
    "                    post_dic[\"title\"] = info_list[1].find_all(\"a\")[0][\"title\"]\n",
    "                    post_dic[\"recommend\"] = info_list[2].text\n",
    "                    post_dic[\"user_id\"] = info_list[3].text.strip(\"\\n\\t\")\n",
    "                    post_dic[\"click\"] = info_list[4].text\n",
    "                    post_dic[\"like\"] = info_list[5].text\n",
    "                    post_dic[\"dislike\"] = info_list[6].text\n",
    "                    post_list.append(post_dic)\n",
    "                else:\n",
    "                    return post_list\n",
    "        page_num += 1\n",
    "   \n",
    "    return post_list  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_all_stock_forum():\n",
    "    \n",
    "    fieldnames = [\"time\", \"title\", \"recommend\", \"user_id\", \"click\", \"like\", \"dislike\"]\n",
    "    for stock in code_df.code:\n",
    "        post_list = scrape_discussion(stock)\n",
    "        file_name = code_df[code_df.code == stock].name.values[0] + \".csv\"\n",
    "        with open(file_name, \"w\") as f:\n",
    "            writer = csv.DictWriter(f, fieldnames = fieldnames)\n",
    "            writer.writeheader()\n",
    "            for post in post_list:\n",
    "                print(post)\n",
    "                writer.writerow(post)\n",
    "    return"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
