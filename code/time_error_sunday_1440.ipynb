{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "import bs4\n",
    "import urllib3\n",
    "from datetime import datetime, tzinfo, timedelta\n",
    "from pytz import timezone\n",
    "\n",
    "def scrape_price_history(code, time):\n",
    "    '''\n",
    "    Scrape the history price information and store it inside a dictionary\n",
    "    of the given stock in the given date and time(hour and minute. It cannot \n",
    "    scrape information more than ten days before, as long as it's a weekday.\n",
    "    Input: \n",
    "      code: the string of stock code\n",
    "      time: the string of date 201802280901\n",
    "    Return: a dictionary\n",
    "    '''\n",
    "    target = \"http://finance.naver.com/item/sise_time.nhn?code=\" + code + \\\n",
    "             \"&thistime=\" + time + \"01&page=1\"\n",
    "    pm = urllib3.PoolManager()\n",
    "    html = pm.urlopen(url=target, method=\"GET\").data\n",
    "    soup = bs4.BeautifulSoup(html, 'lxml')\n",
    "    data_list = soup.find_all(\"tr\")[2].find_all(\"td\",class_=\"num\")\n",
    "    data_dic = {}\n",
    "    data_dic[\"price\"] = data_list[0].text\n",
    "    image = data_list[1].find(\"img\")\n",
    "    if image != None:\n",
    "        if image[\"alt\"] == \"상승\":\n",
    "            data_dic[\"price_dif\"] = data_list[1].text.strip(\"\\n\\t\")\n",
    "        else:\n",
    "            data_dic[\"price_dif\"] = \"-\" + data_list[1].text.strip(\"\\n\\t\")\n",
    "    else:\n",
    "        data_dic[\"price_dif\"] = 0\n",
    "    data_dic[\"sell\"] = data_list[2].text\n",
    "    data_dic[\"buy\"] = data_list[3].text\n",
    "    data_dic[\"volume\"] = data_list[4].text\n",
    "    data_dic[\"variation\"] = data_list[5].text\n",
    "    \n",
    "    return data_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    with open(\"../raw_data/krx_code.json\", \"r\", encoding=\"UTF-8\") as f:\n",
    "        KRX_CODE = json.load(f)\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(e)\n",
    "\n",
    "try:\n",
    "    with open(\"../raw_data/company_info.json\", 'r', encoding='UTF-8') as f:\n",
    "        COMPANY_INFO = json.load(f)\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combine_price(date, save=False):\n",
    "    '''\n",
    "    Combine price and discussion info into a dataframe with on the given date\n",
    "    and save them in a list\n",
    "    Input:\n",
    "      date: string, e.g. \"2018-03-06\"\n",
    "    Return: a list\n",
    "    '''\n",
    "    df = pd.DataFrame(columns=[\"code\", \"name\", \"time\", \"price\", \\\n",
    "                               \"price_dif\", \"sell\", \"buy\", \"volume\", \\\n",
    "                               \"variation\"])\n",
    "    rv = []\n",
    "    rv.append(df.columns.tolist())\n",
    "\n",
    "    time = []\n",
    "    for hour in range(9,16):\n",
    "        for minute in range(0, 6):\n",
    "            if hour != 15 or minute < 4:\n",
    "                time.append(\"../raw_data/discussion/\" + date + \\\n",
    "                \"_focus/discussion_\" + date + \"-\" + ((\"0\" + str(hour)) \\\n",
    "                if hour <= 9 else str(hour))+ \"-\" + str(minute) + \"0.json\")\n",
    "\n",
    "    for t in time:\n",
    "        try:\n",
    "            with open(t, 'r', encoding='UTF-8') as f:\n",
    "                discussion = json.load(f)\n",
    "\n",
    "        except FileNotFoundError as e:\n",
    "            print(e)\n",
    "            continue\n",
    "\n",
    "        opening_increase = \"../raw_data/price/\" + date + \"_price/\" + date +\\\n",
    "                            \"_opening_increase.json\"\n",
    "\n",
    "        try:\n",
    "            with open(opening_increase, 'r', encoding='UTF-8') as f:\n",
    "                increased = json.load(f)\n",
    "\n",
    "        except FileNotFoundError as e:\n",
    "            print(e)\n",
    "            continue\n",
    "\n",
    "\n",
    "        for d in discussion:\n",
    "            if d[\"name\"] in increased:\n",
    "                row = pd.DataFrame(columns=[\"code\", \"name\", \"time\", \\\n",
    "                                            \"price\", \"price_dif\", \"sell\", \\\n",
    "                                            \"buy\", \"volume\", \"variation\"], \\\n",
    "                                   data = [[KRX_CODE[d[\"name\"]], d[\"name\"], \\\n",
    "                                            d[\"time\"], np.nan, np.nan,\\\n",
    "                                            np.nan, np.nan, np.nan, np.nan]])\n",
    "                df = df.append(row)\n",
    "\n",
    "    df = df.reset_index()\n",
    "    \n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        timestamp = row[\"time\"]\n",
    "        t = re.sub('[ :-]', '', timestamp)\n",
    "\n",
    "        d = scrape_price_history(row[\"code\"], t)\n",
    "\n",
    "        df[\"price\"].iloc[idx] = d[\"price\"]\n",
    "        df[\"price_dif\"].iloc[idx] = d[\"price_dif\"]\n",
    "        df[\"sell\"].iloc[idx] = d[\"sell\"]\n",
    "        df[\"buy\"].iloc[idx] = d[\"buy\"]\n",
    "        df[\"volume\"].iloc[idx] = d[\"volume\"]\n",
    "        df[\"variation\"].iloc[idx] = d[\"variation\"]\n",
    "    \n",
    "    rv = []\n",
    "    rv.append(df.columns.tolist())\n",
    "    for row in df.iterrows():\n",
    "        rv.append(row[1].tolist())\n",
    "\n",
    "    if save:\n",
    "\n",
    "        with open(date + \"_price.json\",\"w\", encoding='UTF-8') as f:\n",
    "            json.dump(rv, f, ensure_ascii=False)\n",
    "\n",
    "    return rv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kospi = {}\n",
    "kosdaq = {}\n",
    "\n",
    "for month in range(2, 4):\n",
    "    for day in range(1, 32):\n",
    "        prefix = \"../raw_data/market/2018-\" + (\"0\" + str(month) if month <= 9 else str(month)) +\\\n",
    "                   \"-\" + (\"0\" + str(day) if day <= 9 else str(day)) + \"_market/\"\n",
    "        for market in (\"KOSPI\", \"KOSDAQ\"):\n",
    "            filename = prefix + market + \"_2018-\" + (\"0\" + str(month) if month <= 9 else str(month)) +\\\n",
    "                       \"-\" + (\"0\" + str(day) if day <= 9 else str(day)) + \".json\"\n",
    "        \n",
    "            try:\n",
    "                with open(filename, 'r', encoding='UTF-8') as f:\n",
    "                    opened = json.load(f)\n",
    "                    \n",
    "                    if market == \"KOSPI\":\n",
    "                        kospi.update(opened)\n",
    "                    else:\n",
    "                        kosdaq.update(opened)\n",
    "\n",
    "            except FileNotFoundError:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "company_df = pd.DataFrame(COMPANY_INFO, columns = [\"name\", \"code\", \\\n",
    "                                                   \"market\", \"size\"])\n",
    "KOSPI = []\n",
    "KOSDAQ = []\n",
    "TRASH = []\n",
    "MKT_CAP = {}\n",
    "\n",
    "for idx, row in company_df.iterrows():\n",
    "    if re.sub('[0-9 ,위]', '', row[\"market\"]) == \"코스피\":\n",
    "        KOSPI.append(row[\"code\"])\n",
    "    elif re.sub('[0-9 ,위]', '', row[\"market\"]) == \"코스닥\":\n",
    "        KOSDAQ.append(row[\"code\"])\n",
    "    else:\n",
    "        TRASH.append(row[\"code\"])    \n",
    "    MKT_CAP[row[\"code\"]] = int(re.sub('[조억원,]', '', row[\"size\"]))\n",
    "\n",
    "\n",
    "COLUMN_DISC =[\"name\", \"time\", \"post_num\", \"unique_id\", \"click\", \\\n",
    "              \"like\", \"dislike\", \"time_1\", \"post_num_1\", \"unique_id_1\", \\\n",
    "              \"click_1\", \"like_1\", \"dislike_1\", \"time_2\", \"post_num_2\", \\\n",
    "              \"unique_id_2\", \"click_2\", \"like_2\", \"dislike_2\", \"time_3\", \\\n",
    "              \"post_num_3\", \"unique_id_3\", \"click_3\", \"like_3\", \"dislike_3\"]\n",
    "\n",
    "COLUMN_PRICE=[\"code\", \"name\", \"time\", \"price\", \"price_dif\", \"sell\", \"buy\", \\\n",
    "              \"volume\", \"variation\", \"time_1\", \"price_1\", \"price_dif_1\", \\\n",
    "              \"sell_1\", \"buy_1\", \"volume_1\", \"variation_1\", \"time_2\", \\\n",
    "              \"price_2\", \"price_dif_2\", \"sell_2\", \"buy_2\", \"volume_2\", \\\n",
    "              \"variation_2\", \"time_3\", \"price_3\", \"price_dif_3\", \"sell_3\", \\\n",
    "              \"buy_3\", \"volume_3\", \"variation_3\"]\n",
    "\n",
    "COLUMN_TOTAL = ['name', 'code', 'time', 'price', 'time_1', \"price_1\", \\\n",
    "                \"price_dif_1\", \"sell_1\", \"buy_1\", \"volume_1\", \\\n",
    "                \"variation_1\", 'post_num_1', 'unique_id_1', 'click_1', \\\n",
    "                'like_1', 'dislike_1', 'time_2', 'price_2', \"price_dif_2\", \\\n",
    "                \"sell_2\", \"buy_2\", \"volume_2\", \"variation_2\", 'post_num_2', \\\n",
    "                'unique_id_2', 'click_2', 'like_2', 'dislike_2', 'time_3', \\\n",
    "                'price_3', \"price_dif_3\", \"sell_3\", \"buy_3\", \"volume_3\", \\\n",
    "                \"variation_3\", 'post_num_3', 'unique_id_3', 'click_3', \\\n",
    "                'like_3', 'dislike_3']\n",
    "\n",
    "VAR_TO_TRANSFORM = ['price', 'price_1', 'price_dif_1', 'sell_1', 'buy_1', \\\n",
    "                    'volume_1', 'variation_1', 'price_2', 'price_dif_2', \\\n",
    "                    'sell_2', 'buy_2', 'volume_2',  'variation_2', \\\n",
    "                    'price_3', 'price_dif_3', 'sell_3', 'buy_3', 'volume_3', \\\n",
    "                    'variation_3']\n",
    "\n",
    "MISSING = [\"2018-02-27 11:30\", \"2018-02-27 11:40\", \"2018-02-27 11:50\", \\\n",
    "            \"2018-02-27 12:00\", \"2018-02-27 12:10\", \"2018-02-27 12:20\", \\\n",
    "            \"2018-02-27 12:30\", \"2018-02-27 12:40\", \"2018-02-27 12:50\", \\\n",
    "            \"2018-02-27 13:00\", \"2018-02-27 13:10\", \"2018-02-27 13:20\", \\\n",
    "            \"2018-02-27 13:30\", \"2018-02-27 13:40\"]\n",
    "\n",
    "PRICE_SINGLE_COL = [\"code\", \"name\", \"time\", \"price\", \"price_dif\", \\\n",
    "                    \"sell\", \"buy\", \"volume\", \"variation\"]\n",
    "\n",
    "SQUARED = ['price_1', 'price_dif_1', 'sell_1', 'buy_1', 'volume_1', \\\n",
    "         'variation_1', 'post_num_1', 'unique_id_1', 'click_1', 'like_1', \\\n",
    "         'dislike_1', 'price_2', 'price_dif_2', 'sell_2', 'buy_2', \\\n",
    "         'volume_2', 'variation_2', 'post_num_2', 'unique_id_2', 'click_2', \\\n",
    "         'like_2', 'dislike_2', 'price_3', 'price_dif_3', 'sell_3', 'buy_3', \\\n",
    "         'volume_3', 'variation_3', 'post_num_3', 'unique_id_3', 'click_3', \\\n",
    "         'like_3', 'dislike_3', 'mkt_cap', 'yesterday_closing_price', \\\n",
    "         'price_volatility', 'price_trend', 'average_price_volatility', \\\n",
    "         'sell_minus_buy_1', 'sell_minus_buy_2', 'sell_minus_buy_3', \\\n",
    "         'price_gap_volatility', 'volume_trend', 'post_num_trend', \\\n",
    "         'unique_id_trend', 'click_trend', 'kospi_ind', 'kosdaq_ind', \\\n",
    "         'time_slot', 'ko_inter', 'mkt_change', 'alpha', 'per_now', \\\n",
    "         'kospi_1', 'kospi_2', 'kospi_3', 'kosdaq_1', 'kosdaq_2', \\\n",
    "         'kosdaq_3', 'kospi_trend', 'kosdaq_trend']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def open_files(date):\n",
    "    ''''\n",
    "    Open files for making data frame for the specific date\n",
    "    Input:\n",
    "      date: string of date, e.g. '2018-03-06', only apply to Feburary 14, 20, 21, \n",
    "            22, 23, 26, 27, 28, and March 2, 3, 6 ,7\n",
    "    Return: dictionary, dictionary\n",
    "    '''\n",
    "    focus_text = \"../raw_data/discussion/\" + date + \"_focus/\" +\\\n",
    "                 date + \"_focus_group.json\"\n",
    "\n",
    "    price_text = \"../raw_data/price/\" + date + \"_price/\" +\\\n",
    "                 date + \"_price.json\"\n",
    "    \n",
    "    with open(focus_text, 'r', encoding='UTF-8') as f:\n",
    "        focus_group = json.load(f)\n",
    "    with open(price_text, 'r', encoding='UTF-8') as f:\n",
    "        price = json.load(f)\n",
    "    \n",
    "    return focus_group, price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_single_time(prefix, hour, minute):\n",
    "    '''\n",
    "    Get a string of time based on given prefix, hour and min\n",
    "    \n",
    "    Inputs:\n",
    "      prefix: string of path, e.g. \"2018-02-28_focus/discussion_2018-02-28\"\n",
    "      hour: integer of hour, from 9 to 15\n",
    "      min: integer of min, from 0 to 6\n",
    "    Return: a string of path\n",
    "    '''\n",
    "    if 9 <= hour <= 15 and 0 <= minute <= 6:\n",
    "        if hour == 15 and minute > 3:\n",
    "            return None\n",
    "        \n",
    "        return prefix + \"-\" + ((\"0\" + str(hour)) if hour <= 9 else str(hour)) +\\\n",
    "               \"-\" + str(minute) + \"0.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_time_disc(date):\n",
    "    '''\n",
    "    Get the list for discussion data filenames of different time for the \n",
    "    specific day, e.g. from 2018-03-06 9 am to 3 pm every ten minutes. \n",
    "    Input:\n",
    "      date: string of date, e.g. 2018-03-06, only apply to Feburary 14, 20, \n",
    "            21, 22, 23, 26, 27, 28, and March 2, 3, 6 ,7\n",
    "    Return: a list\n",
    "    '''\n",
    "    time = []\n",
    "    prefix = \"../raw_data/discussion/\" + date + \"_focus/discussion_\" + date\n",
    "    month = date[6]\n",
    "    day = date[8:]\n",
    "    if month == \"2\":\n",
    "        for hour in range(9,16):        \n",
    "            if day == \"26\" and hour == 9:\n",
    "                continue        \n",
    "            elif day == \"27\" and hour == 11:\n",
    "                continue            \n",
    "            for minute in range(0, 6):\n",
    "                if hour == 15 and minute > 3:\n",
    "                    break\n",
    "                if day == \"26\" and hour == 10 and minute == 0:\n",
    "                    continue            \n",
    "                elif day == \"27\" and hour == 10 and minute > 2:\n",
    "                    continue            \n",
    "                elif day == \"27\" and hour == 12 and minute < 3:\n",
    "                    continue            \n",
    "                time.append(get_single_time(prefix, hour, minute))            \n",
    "    elif month == \"3\":  \n",
    "        for hour in range(9,16):    \n",
    "            if day == \"02\" and hour == 9:\n",
    "                continue        \n",
    "            elif day == \"02\" and hour == 10:\n",
    "                continue        \n",
    "            elif day == \"02\" and hour == 15:\n",
    "                continue            \n",
    "            for minute in range(0, 6):\n",
    "                if hour == 15 and minute > 3:\n",
    "                    break\n",
    "                if day == \"02\" and hour == 11 and minute < 5:\n",
    "                    continue            \n",
    "                elif day == \"02\" and hour == 14 and minute > 4:\n",
    "                    continue            \n",
    "                time.append(get_single_time(prefix, hour, minute))       \n",
    "    \n",
    "    return time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def df_list_disc(date):\n",
    "    '''\n",
    "    Store all the discussion file of a given date and store them as a \n",
    "    dataframein a list.\n",
    "    Input:\n",
    "      date: string of date, e.g. 2018-03-06\n",
    "    Return: a list of dataframe\n",
    "    '''\n",
    "    df_list = []\n",
    "    time = get_time_disc(date)\n",
    "    for x in time:\n",
    "        with open(x, 'r', encoding='UTF-8') as f:\n",
    "            discussion = json.load(f)        \n",
    "            discuss_df = pd.DataFrame(discussion, columns = [\"post_num\", \\\n",
    "                                \"unique_id\", \"click\", \"like\", \"dislike\", \n",
    "                                \"name\", \"time\"])\n",
    "            reset_col = [\"name\", \"time\", \"post_num\", \"unique_id\", \"click\", \\\n",
    "                         \"like\", \"dislike\"]\n",
    "            discuss_df = discuss_df[reset_col]\n",
    "            df_list.append(discuss_df)\n",
    "\n",
    "    return df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def list_to_df(date, df_list, column_names, key_list):\n",
    "    ''''\n",
    "    Merge the dataframes in the list in a specific date\n",
    "    into a total dataframe based on the gap of prediction.\n",
    "    Inputs:\n",
    "      date: string of date, e.g. 2018-03-06\n",
    "      df_list: a list of dataframe\n",
    "      column_names: list of columns\n",
    "      key_list: list of columns to merge data frames\n",
    "    Return: a dataframe\n",
    "    '''\n",
    "    total = pd.DataFrame(columns=column_names)\n",
    "    for ind, df in enumerate(df_list):\n",
    "        \n",
    "        if ind >= 8:\n",
    "            df_total = df.merge(df_list[ind - 8], on = \\\n",
    "                                key_list).merge(df_list[ind - 9], \\\n",
    "                                on = key_list).merge(df_list[ind - 10], \\\n",
    "                                on = key_list)\n",
    "            df_total.columns = column_names\n",
    "            total = pd.concat([total, df_total], axis = 0)\n",
    "\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_discuss_df(date):\n",
    "    '''\n",
    "    Get total dataframe of discussion from raw files\n",
    "    Input:\n",
    "      date: string of date, e.g. 2018-03-06\n",
    "    Return: a dataframe\n",
    "    '''\n",
    "    discussion_list = df_list_disc(date)\n",
    "    discuss_df = list_to_df(date, discussion_list, COLUMN_DISC, \n",
    "                            ['name']).reset_index().drop([\"index\"], \\\n",
    "                            axis = 1)\n",
    "\n",
    "    return discuss_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def df_list_price(date):\n",
    "    '''\n",
    "    Get the dataframes of price during different time within a day and store \n",
    "    them in a list. \n",
    "    Input:\n",
    "      date: string of date, e.g. 2018-03-06\n",
    "    Return: a list\n",
    "    '''\n",
    "    focus, price = open_files(date)\n",
    "    price_df = pd.DataFrame(price, columns = [\"index\", \"code\", \"name\", \\\n",
    "                                              \"time\", \"price\", \"price_dif\", \\\n",
    "                                              \"sell\", \"buy\", \"volume\", \\\n",
    "                                              \"variation\"])\n",
    "    price_df = price_df[PRICE_SINGLE_COL][1:]\n",
    "    text = date + \" 09:00\"\n",
    "    price_df = price_df[price_df[\"time\"] != text]\n",
    "    time_list = price_df['time'].unique().tolist()\n",
    "    price_df_list = []\n",
    "    for time in time_list:\n",
    "        df = price_df[price_df[\"time\"] == time]\n",
    "        df = df[PRICE_SINGLE_COL]\n",
    "        price_df_list.append(df)\n",
    "        \n",
    "    return price_df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_price_df(date):\n",
    "    '''\n",
    "    Transform all the raw price files into a data frame\n",
    "    Input:\n",
    "      date: string of date, e.g. 2018-03-06\n",
    "    Return: a datafame\n",
    "    '''\n",
    "    price_df_list = df_list_price(date)\n",
    "    price_df = list_to_df(date, price_df_list, COLUMN_PRICE, \\\n",
    "                          ['code', 'name']).reset_index().drop([\"index\"], axis = 1)\n",
    "    \n",
    "    return price_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_total_df(date):\n",
    "    '''\n",
    "    Get a total data frame from raw data with both price and discussion \n",
    "    information.\n",
    "    Input:\n",
    "      date: string of date, e.g. 2018-03-06\n",
    "    Return: a datafame\n",
    "    '''\n",
    "    price_df = get_price_df(date)\n",
    "    discuss_df = get_discuss_df(date)\n",
    "    total_df = pd.merge(price_df, discuss_df, on = ['name', \\\n",
    "                                                    'time', 'time_1', \\\n",
    "                                                    'time_2', 'time_3'])\n",
    "    total_df = total_df[COLUMN_TOTAL]\n",
    "    \n",
    "    return total_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_company(date):\n",
    "    '''\n",
    "    Add company info to the dataframe created from the price and discussion\n",
    "    raw data.\n",
    "    Input:\n",
    "      date: string of date, e.g. 2018-03-06\n",
    "    Return: a dataframe\n",
    "    '''\n",
    "    total = get_total_df(date)\n",
    "    total[\"mkt_cap\"] = np.nan\n",
    "    total[\"kospi\"] = np.nan\n",
    "    total[\"kosdaq\"] = np.nan\n",
    "    total[\"trash\"] = np.nan\n",
    "    \n",
    "    for index, row in total.iterrows():\n",
    "        mkt_cap = MKT_CAP[row[\"code\"]]\n",
    "\n",
    "        kospi_dummy = 1 if row[\"code\"] in KOSPI else 0\n",
    "\n",
    "        kosdaq_dummy = 1 if row[\"code\"] in KOSDAQ else 0\n",
    "\n",
    "        trash = 1 if row[\"code\"] in TRASH else 0\n",
    "\n",
    "        total.set_value(index,\"mkt_cap\", mkt_cap)\n",
    "        total.set_value(index,\"kospi\", kospi_dummy)\n",
    "        total.set_value(index,\"kosdaq\", kosdaq_dummy)\n",
    "        total.set_value(index,\"trash\", trash)  \n",
    "    \n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_df(date):\n",
    "    '''\n",
    "    Return a total data frame created from market, price and discussion \n",
    "    raw data with all numeriacal variables' values as floats. \n",
    "    Input:\n",
    "      date: string of date, e.g. 2018-03-06\n",
    "    Return: a dataframe\n",
    "    '''\n",
    "    total = add_company(date)\n",
    "    total.dropna(inplace = True)\n",
    "    for var in VAR_TO_TRANSFORM:\n",
    "        total = total[total[var] != '\\xa0']\n",
    "        for index, row in total.iterrows():\n",
    "            if isinstance(row[var], str):\n",
    "                data = row[var].split(\",\")\n",
    "                value = ''.join(data)\n",
    "                value = int(value)\n",
    "                total.set_value(index, var, value)\n",
    "\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def total_date_df(dates):\n",
    "    '''\n",
    "    Make a complete dataframe with info from raw data of discussion, \n",
    "    price and market index combining specidfic dates defined. \n",
    "    Inputs:\n",
    "      dates: list of dates, e.g. ['2018-02-28', '2018-03-02']\n",
    "    Return: a dataframe\n",
    "    '''\n",
    "    total_df = pd.DataFrame(columns=COLUMN_TOTAL)\n",
    "    for date in dates:\n",
    "        df = transform_df(date)\n",
    "        if date == '2018-02-27':\n",
    "            df = df[~df['time'].isin(MISSING)]\n",
    "        total_df = pd.concat([total_df, df])\n",
    "    total_df = total_df.reset_index().drop([\"index\"], axis = 1)\n",
    "\n",
    "    return total_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def complete_df(dates):\n",
    "    '''\n",
    "    Make a complete dataframe with modified variables ready for analyze.\n",
    "    Input:\n",
    "      dates: a list of dates to mark the data\n",
    "    Return: a dataframe     \n",
    "    '''\n",
    "    total_df = total_date_df(dates)\n",
    "    total_df[\"yesterday_closing_price\"] = total_df[\"price_1\"] - \\\n",
    "                                          total_df[\"price_dif_1\"]\n",
    "    total_df[\"is_maximum\"] = (((total_df[\"price_1\"] / \\\n",
    "                             total_df[\"yesterday_closing_price\"]) - 1) * \\\n",
    "                             100 > 29.5) | (((total_df[\"price_2\"] / \\\n",
    "                             total_df[\"yesterday_closing_price\"]) - 1) * \\\n",
    "                             100 > 29.5) | (((total_df[\"price_3\"] / \\\n",
    "                             total_df[\"yesterday_closing_price\"]) - 1) * \\\n",
    "                             100 > 29.5)\n",
    "    total_df[\"is_maximum\"] = total_df[\"is_maximum\"].astype(int)\n",
    "\n",
    "    total_df[\"is_minimum\"] = (((total_df[\"price_1\"] / \\\n",
    "                             total_df[\"yesterday_closing_price\"]) - 1) * \\\n",
    "                             100 < -29.5) | (((total_df[\"price_2\"] / \\\n",
    "                             total_df[\"yesterday_closing_price\"]) - 1) * \\\n",
    "                             100 < -29.5) | (((total_df[\"price_3\"] / \\\n",
    "                             total_df[\"yesterday_closing_price\"]) - 1) * \\\n",
    "                             100 < -29.5)\n",
    "\n",
    "    total_df[\"is_minimum\"] = total_df[\"is_maximum\"].astype(int)\n",
    "\n",
    "    total_df[\"price_volatility\"] = (((total_df[[\"price_1\", \"price_2\", \\\n",
    "                                   \"price_3\"]].max(axis=1)) / \\\n",
    "                                   (total_df[[\"price_1\", \"price_2\", \\\n",
    "                                    \"price_3\"]].min(axis=1))) - 1) * 100\n",
    "\n",
    "    total_df[\"price_trend\"] = (((total_df[\"price_1\"] - \\\n",
    "                              total_df[\"price_2\"]) < 0).astype(int) + \\\n",
    "                              ((total_df[\"price_2\"] - total_df[\"price_3\"]) < \\\n",
    "                              0).astype(int)) - (((total_df[\"price_1\"] - \\\n",
    "                              total_df[\"price_2\"]) > 0).astype(int) + \\\n",
    "                              ((total_df[\"price_2\"] - total_df[\"price_3\"]) > \\\n",
    "                              0).astype(int))\n",
    "\n",
    "    total_df[\"average_price_volatility\"] = total_df[\"price_trend\"] * \\\n",
    "                                           total_df[\"price_volatility\"] / 2\n",
    "    \n",
    "    for i in range(1, 4):\n",
    "        minus, sell, buy = \"sell_minus_buy_\" + str(i), \"sell_\" + str(i), \\\n",
    "                           \"buy_\" + str(i)\n",
    "        total_df[minus] = total_df[sell] - total_df[buy]\n",
    "\n",
    "    total_df[\"is_price_gap_stable\"] = ((total_df[\"sell_minus_buy_1\"] == \\\n",
    "                                      total_df[\"sell_minus_buy_2\"]) & \\\n",
    "                                      (total_df[\"sell_minus_buy_2\"] == \\\n",
    "                                   total_df[\"sell_minus_buy_3\"])).astype(int)\n",
    "\n",
    "    total_df[\"price_gap_volatility\"] = (((total_df[[\"sell_minus_buy_1\", \\\n",
    "                                       \"sell_minus_buy_2\", \n",
    "                                       \"sell_minus_buy_3\"]].max(axis=1)) / \\\n",
    "                                       (total_df[[\"sell_minus_buy_1\", \\\n",
    "                                       \"sell_minus_buy_2\", \\\n",
    "                                       \"sell_minus_buy_3\"]].min(axis=1)))) - 1\n",
    "\n",
    "    total_df[\"is_like_higher\"] = (total_df[\"like_3\"] > \\\n",
    "                                 total_df[\"dislike_3\"]).astype(int)\n",
    "    \n",
    "    disc_trend = [\"volume\", \"post_num\", \"unique_id\", \"click\"]\n",
    "    for var in disc_trend:\n",
    "        r_var = var + \"_trend\"\n",
    "        var_3, var_2, var_1 = var + \"_3\", var + \"_2\", var + \"_1\"\n",
    "        total_df[r_var] = ((((total_df[var_3]) - \\\n",
    "                            (total_df[var_2] * 1+1e-3)) / \\\n",
    "                            ((total_df[var_2]) - (total_df[var_1] * \\\n",
    "                            1-1e-4))) - 1) * 100\n",
    "\n",
    "    total_df[\"price_increase\"] = ((total_df[\"price\"] / total_df[\"price_3\"]) \\\n",
    "                                   - 1) * 100\n",
    "\n",
    "    total_df[\"did_price_increase\"] = (total_df[\"price_increase\"] > \\\n",
    "                                      0).astype(int)\n",
    "\n",
    "    total_df[\"did_price_033\"] = (total_df[\"price_increase\"] > \\\n",
    "                                 0.33).astype(int)\n",
    "\n",
    "    total_df[\"did_price_100\"] = (total_df[\"price_increase\"] > 1.0).astype(int)\n",
    "\n",
    "    total_df[\"did_price_150\"] = (total_df[\"price_increase\"] > 1.5).astype(int)\n",
    "    \n",
    "    mkt_time_new = [\"kospi_ind\", \"kosdaq_ind\", \"time_slot\", \"ko_inter\", \\\n",
    "                    \"early_mor\", \"morning\", \"lunch\", \"afternoon\", \"late\", \\\n",
    "                    \"mkt_change\", \"alpha\", \"per_now\", \"kospi_1\", \"kospi_2\", \\\n",
    "                    \"kospi_3\", \"kospi_answer\", \"kosdaq_1\", \"kosdaq_2\", \\\n",
    "                    \"kosdaq_3\", \"kosdaq_answer\"]\n",
    "    for var in mkt_time_new:\n",
    "        total_df[var] = np.nan\n",
    "    num = 1\n",
    "    time_list = []\n",
    "    for index, row in total_df.iterrows():\n",
    "        kospi_ind = kospi[row['time']]\n",
    "        kosdaq_ind = kosdaq[row['time']]\n",
    "        total_df.set_value(index,'kospi_ind', kospi_ind)\n",
    "        total_df.set_value(index,'kosdaq_ind', kosdaq_ind)\n",
    "        time = row['time'].split()[1]\n",
    "        if time not in time_list:\n",
    "            time_list.append(time)\n",
    "        ind = time_list.index(time)\n",
    "        num = index + 1\n",
    "\n",
    "        early_mor = 1 if num in [1, 2, 3] else 0\n",
    "\n",
    "        morning = 1 if (num >= 1) and (num <= 15) else 0\n",
    "\n",
    "        lunch = 1 if (num >= 16) and (num <= 24) else 0\n",
    "    \n",
    "        afternoon = 1 if (num >= 25) and (num <= 36) else 0\n",
    "\n",
    "        late = 1 if (num >= 31) and (num <= 36) else 0\n",
    "\n",
    "        mkt_change = row['kospi'] * kospi_ind + row['kosdaq'] * kosdaq_ind\n",
    "        total_df.set_value(index,'mkt_change', mkt_change)\n",
    "        total_df.set_value(index,'early_mor', early_mor)\n",
    "        total_df.set_value(index,'morning', morning)\n",
    "        total_df.set_value(index,'lunch', lunch)\n",
    "        total_df.set_value(index,'afternoon', afternoon)\n",
    "        total_df.set_value(index,'late', late)\n",
    "        total_df.set_value(index,'time_slot', num)\n",
    "        total_df.set_value(index,'ko_inter', kospi_ind * kosdaq_ind)\n",
    "        per_now = 100 * row['price_dif_3']/row['yesterday_closing_price']\n",
    "        total_df.set_value(index, 'per_now', per_now)\n",
    "        alpha = per_now - mkt_change\n",
    "        total_df.set_value(index, 'alpha', alpha)\n",
    "        \n",
    "        last_closing = row[\"time\"][:10] + \" last_closing\"\n",
    "        \n",
    "        total_df.set_value(index, 'kospi_1', (kospi[row[\"time_1\"]] / kospi[last_closing] - 1) * 100)\n",
    "        total_df.set_value(index, 'kospi_2', (kospi[row[\"time_2\"]] / kospi[last_closing] - 1) * 100)\n",
    "        total_df.set_value(index, 'kospi_3', (kospi[row[\"time_3\"]] / kospi[last_closing] - 1) * 100)\n",
    "        total_df.set_value(index, 'kospi_answer', kospi[row[\"time\"]])\n",
    "     \n",
    "        total_df.set_value(index, 'kosdaq_1', (kosdaq[row[\"time_1\"]] / kosdaq[last_closing] - 1) * 100)\n",
    "        total_df.set_value(index, 'kosdaq_2', (kosdaq[row[\"time_2\"]] / kosdaq[last_closing] - 1) * 100)\n",
    "        total_df.set_value(index, 'kosdaq_3', (kosdaq[row[\"time_3\"]] / kosdaq[last_closing] - 1) * 100)\n",
    "        total_df.set_value(index, 'kosdaq_answer', kosdaq[row[\"time\"]])\n",
    "\n",
    "    total_df[\"kospi_trend\"] = ((((total_df[\"kospi_3\"]) - \\\n",
    "                              (total_df[\"kospi_2\"] * 1+1e-3)) / \\\n",
    "                              ((total_df[\"kospi_2\"]) - (total_df[\"kospi_1\"] \\\n",
    "                              * 1-1e-4))) - 1) * 100\n",
    "\n",
    "    total_df[\"kosdaq_trend\"] = ((((total_df[\"kosdaq_3\"]) - \\\n",
    "                               (total_df[\"kosdaq_2\"] * 1+1e-3)) / \\\n",
    "                               ((total_df[\"kosdaq_2\"]) - \\\n",
    "                               (total_df[\"kosdaq_1\"] * 1-1e-4))) - 1) * 100\n",
    "\n",
    "    total_df[\"kospi_increase\"] = 100 * (total_df[\"kospi_answer\"] - \\\n",
    "                                 total_df[\"kospi_3\"]) / total_df[\"kospi_3\"]\n",
    "\n",
    "    total_df[\"kosdaq_increase\"] = 100 * (total_df[\"kosdaq_answer\"] - \\\n",
    "                                  total_df[\"kosdaq_3\"]) / total_df[\"kosdaq_3\"]\n",
    "\n",
    "    total_df[\"market_increase\"] = (total_df[\"kospi\"] * \\\n",
    "                                   total_df[\"kospi_increase\"]) + \\\n",
    "                                  (total_df[\"kosdaq\"] * \\\n",
    "                                   total_df[\"kosdaq_increase\"])\n",
    "    \n",
    "    total_df[\"did_opening_price_increase\"] = 1\n",
    "\n",
    "    for var in SQUARED:\n",
    "        col_name = var + '_sq'\n",
    "        total_df[col_name] = np.nan\n",
    "        for index, row in total_df.iterrows():\n",
    "            sqr = row[var] ** 2\n",
    "            total_df.set_value(index, col_name, sqr)\n",
    "\n",
    "\n",
    "    return total_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ki = complete_df([\"2018-02-26\", \"2018-02-27\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time_1    2018-02-26 10:10\n",
       "time_2    2018-02-26 15:30\n",
       "time_3    2018-02-26 15:20\n",
       "time      2018-02-26 11:30\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ki.iloc[0][[\"time_1\", \"time_2\", \"time_3\", \"time\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATES = ['2018-02-14', '2018-02-20', '2018-02-21', '2018-02-22', \\\n",
    "         '2018-02-23', '2018-02-26', '2018-02-27', '2018-02-28', \\\n",
    "         '2018-03-02', '2018-03-05', '2018-03-06', '2018-03-07']\n",
    "\n",
    "total_df = complete_df(DATES)\n",
    "#total_df.to_json('df_Mar_07.json', orient='values')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
